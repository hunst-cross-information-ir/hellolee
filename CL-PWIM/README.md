# CL-PWIM
实验步骤如下：

step1：

将双语词向量整合到一起。这里我们用的已经训练好的双语词向量，但是训练完成的文件有2个，因此我们将其整合到一起。双语词向量的训练可以参照facebook团队的代码实现步骤https://github.com/facebookresearch/MUSE

step2：

训练PWIM模型。我们的训练语料是直接从网上下载到本地，网址为：http://www.statmt.org/europarl/

step3：

文档处理。这里我们对文档进行预处理，主要包括分句、分词、去停用词以及词干化等操作，不在检索当中进行处理是因为文档处理需要一定时间，我们处理完保存会更好。

step4：

检索。得到查询和文档的得分。

step5：

写入结果文件。根据上步产生的文档得分.npy文件，经过处理排序写入.txt文件。

step6：

根据结果文件评估MAP。


本文的实验中有许多的参数可以调节，模型中的参数我是直接引用别人的模型，只修改了训练轮数和批大小。我们自己的参数包括抽样文档数、训练句子负样例数目等等。

实验的相关文件功能说明如下：

topmix_.py

将原始查询和文档得分与我们CL-PWIM方法得分之和作为查询和文档的最终得分，采用线性拟合的方式。S=k*S1+(1-k)*S2

这里S2代表原始查询和文档的得分，我们用的是TbTQT的方法，具体可以采用其它方法来替换，而S1代表CL-PWIM得分，我们根据前人的经验，选取文档中得分高的句子，并赋予不同的权重，最终文档与查询得分是这些句子得分与对应权重乘积之和。因为权重需要调节，我们在[0,1]区间，按照0.1的间隔，对前面的三个句子微调。另外还有个需要调节的部分，是TbTQT和CL-PWIM方法的混合比例，我们同样选取[0,1]之间的值，以0.1作为间隔。

evalution_topn.py

对不同权重值的检索结果进行评估，输出得分前10的句子权重赋值以及对应的检索得分。需要注意的是，每次评估的是一个对应的K值下的检索得分。

do_topmix.py

当已经求得表现优秀的句子权重赋值的时候，这里调用固定的权重赋值，之后便只考虑K的赋值，最终得到不同K值下混合检索得分。

实验如存在问题，可以联系作者。邮箱：857243838@qq.com
